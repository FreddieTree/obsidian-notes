---
title: Structured information extraction from scientific text with large language models
authors: John Dagdelen, Alexander Dunn, Sanghoon Lee, Nicholas Walker, Andrew S. Rosen, Gerbrand Ceder, Kristin A. Persson, Anubhav Jain
date: 2024-02-15
tags: 
DOI: [10.1038/s41467-024-45563-x](https://doi.org/10.1038/s41467-024-45563-x)
---

# 📖 Structured information extraction from scientific text with large language models

### 📌 Basic Information
- **Authors**: John Dagdelen, Alexander Dunn, Sanghoon Lee, Nicholas Walker, Andrew S. Rosen, Gerbrand Ceder, Kristin A. Persson, Anubhav Jain
- **Publication Date**: 2024-02-15
- **DOI**: [10.1038/s41467-024-45563-x](https://doi.org/10.1038/s41467-024-45563-x)
- **Tags**: 

---

## 📝 Summary
> Abstract
            Extracting structured knowledge from scientific text remains a challenging task for machine learning models. Here, we present a simple approach to joint named entity recognition and relation extraction and demonstrate how pretrained large language models (GPT-3, Llama-2) can be fine-tuned to extract useful records of complex scientific knowledge. We test three representative tasks in materials chemistry: linking dopants and host materials, cataloging metal-organic frameworks, and general composition/phase/morphology/application information extraction. Records are extracted from single sentences or entire paragraphs, and the output can be returned as simple English sentences or a more structured format such as a list of JSON objects. This approach represents a simple, accessible, and highly flexible route to obtaining large databases of structured specialized scientific knowledge extracted from research papers.

---

## ✏️ Annotations


---

## 🧐 Personal Notes
🔍 **Key Takeaways**  
- _Write your insights and reflections here._

📌 **Important Concepts**  
- _Concept 1_  
- _Concept 2_

❓ **Questions for Further Research**  
- _List questions or points you need to explore further._

---

## 📚 References
[1]

J. Dagdelen _et al._, ‘Structured information extraction from scientific text with large language models’, _Nat Commun_, vol. 15, no. 1, p. 1418, Feb. 2024, doi: [10.1038/s41467-024-45563-x](https://doi.org/10.1038/s41467-024-45563-x).