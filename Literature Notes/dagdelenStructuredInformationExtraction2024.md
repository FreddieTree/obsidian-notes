# Structured information extraction from scientific text with large language models

<!-- Collapsible Basic Information -->
<details>
  <summary>📌 Basic Information</summary>
  
  - **Authors:** John Dagdelen, Alexander Dunn, Sanghoon Lee, Nicholas Walker, Andrew S. Rosen, Gerbrand Ceder, Kristin A. Persson, Anubhav Jain
  - **Publication Date:** 2024-02-15
  
  - **DOI:** [10.1038/s41467-024-45563-x](https://doi.org/10.1038/s41467-024-45563-x)
  
  - **Tags:** 
  
</details>

---

## 📝 Summary
> Abstract
            Extracting structured knowledge from scientific text remains a challenging task for machine learning models. Here, we present a simple approach to joint named entity recognition and relation extraction and demonstrate how pretrained large language models (GPT-3, Llama-2) can be fine-tuned to extract useful records of complex scientific knowledge. We test three representative tasks in materials chemistry: linking dopants and host materials, cataloging metal-organic frameworks...

---

## ✏️ Annotations


---

## 🧐 Personal Notes

### 🔍 Key Takeaways  
- *Write your insights and reflections here.*

### 📌 Important Concepts  
- *Concept 1*  
- *Concept 2*

### ❓ Questions for Further Research  
- *List questions or points you need to explore further.*

---

## 📚 References
[1]

J. Dagdelen _et al._, ‘Structured information extraction from scientific text with large language models’, _Nat Commun_, vol. 15, no. 1, p. 1418, Feb. 2024, doi: [10.1038/s41467-024-45563-x](https://doi.org/10.1038/s41467-024-45563-x).