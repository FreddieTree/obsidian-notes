# Structured information extraction from scientific text with large language models

<!-- Collapsible Basic Information -->
<details>
  <summary>ğŸ“Œ Basic Information</summary>
  
  - **Authors:** John Dagdelen, Alexander Dunn, Sanghoon Lee, Nicholas Walker, Andrew S. Rosen, Gerbrand Ceder, Kristin A. Persson, Anubhav Jain
  - **Publication Date:** 2024-02-15
  
  - **DOI:** [10.1038/s41467-024-45563-x](https://doi.org/10.1038/s41467-024-45563-x)
  
  - **Tags:** 
  
</details>

---

## ğŸ“ Summary
> Abstract
            Extracting structured knowledge from scientific text remains a challenging task for machine learning models. Here, we present a simple approach to joint named entity recognition and relation extraction and demonstrate how pretrained large language models (GPT-3, Llama-2) can be fine-tuned to extract useful records of complex scientific knowledge. We test three representative tasks in materials chemistry: linking dopants and host materials, cataloging metal-organic frameworks...

---

## âœï¸ Annotations


---

## ğŸ§ Personal Notes

### ğŸ” Key Takeaways  
- *Write your insights and reflections here.*

### ğŸ“Œ Important Concepts  
- *Concept 1*  
- *Concept 2*

### â“ Questions for Further Research  
- *List questions or points you need to explore further.*

---

## ğŸ“š References
[1]

J. Dagdelen _et al._, â€˜Structured information extraction from scientific text with large language modelsâ€™, _Nat Commun_, vol. 15, no. 1, p. 1418, Feb. 2024, doi: [10.1038/s41467-024-45563-x](https://doi.org/10.1038/s41467-024-45563-x).